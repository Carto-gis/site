{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0018624d-800f-408d-bae9-a1b32f37a7bb",
   "metadata": {},
   "source": [
    "# A Local Static Map - Visualizing PPGIS Data from Helsinki\n",
    "\n",
    "In this tutorial, we will work with a PPGIS dataset from Helsinki and explore methods to create a local map of our data. Public Participation Geographic Information Systems (PPGIS) blend GIS technologies with public participation processes for a more inclusive approach to spatial planning and policymaking. PPGIS utilizes map-based surveys and geospatial tools to gather public feedback on projects like urban development, environmental conservation, and transportation planning. Its key focus is enabling communities to contribute directly to the planning process, ensuring decisions are democratic, equitable, and informed. Learn more about PPGIS [here](https://en.wikipedia.org/wiki/Participatory_GIS).\n",
    "\n",
    "We're using an open, anonymized dataset from the Zenodo [repository](https://zenodo.org/records/3621342), collected as part of the Urban Happiness project at Aalto University. It includes datasets on home locations, everyday errands, and experience points in Helsinki and Espoo. This tutorial focuses on Helsinki's experiential data, representing places marked by participants. We're particularly interested in the `Quality` column, which indicates whether places are perceived as *Positive* or *Negative*.\n",
    "\n",
    "The main aim of this tutorial is to explore different visual options. Throughout this tutorial, we'll create various visualizations using vector data, practicing:\n",
    "\n",
    "- Basic point maps\n",
    "- Adding basemaps to static maps\n",
    "- Manipulating and classifying data to enhance maps\n",
    "- Visualizing large point datasets to identify patterns\n",
    "- Working with map legends\n",
    "- Adding a scalebar\n",
    "- Adding custom symbols and labels to maps\n",
    "- Creating kernel density estimate maps\n",
    "\n",
    "We'll explore different Python libraries, each with unique strengths in handling and visualizing geospatial data:\n",
    "\n",
    "- **Numpy**: Essential for scientific computing and handling arrays. [Numpy Documentation](https://numpy.org/doc/)\n",
    "- **Pandas**: Provides high-performance data structures and analysis tools. [Pandas Documentation](https://pandas.pydata.org/pandas-docs/stable/)\n",
    "- **Osmnx**: Facilitates the download and analysis of street networks from OpenStreetMap. [Osmnx Documentation](https://osmnx.readthedocs.io/en/stable/)\n",
    "- **Geopandas**: Extends pandas for geospatial data operations. [Geopandas Documentation](https://geopandas.org/en/stable/)\n",
    "- **Matplotlib**: Our primary tool for static, interactive, and animated visualizations. [Matplotlib Documentation](https://matplotlib.org/contents.html)\n",
    "- **Contextily**: Adds basemaps to matplotlib figures. [Contextily Documentation](https://contextily.readthedocs.io/en/latest/)\n",
    "- **TileMapBase**: Yet another library for adding basemaps to our map. [TileMapBase Documentation](https://github.com/MatthewDaws/TileMapBase).\n",
    "- **Seaborn**: Offers a higher-level interface for attractive statistical graphics, built on Matplotlib. [Seaborn Documentation](https://seaborn.pydata.org/)\n",
    "\n",
    "By the end of this tutorial, you'll have the skills to create static visualizations of local geospatial data and uncover insights from datasets. Let's get started!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db54f06d-ab63-4340-b4b6-29da62f9efc0",
   "metadata": {},
   "source": [
    "## Data exploration\n",
    "\n",
    "We start by importing and exploring our data using Geopandas library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b90fc9-887b-477b-a9bc-54d84421989c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pathlib\n",
    "\n",
    "# Path to our Experience data from Helsinki\n",
    "# set the paths\n",
    "NOTEBOOK_PATH = pathlib.Path().resolve()\n",
    "\n",
    "# We will export the final map here,\n",
    "# letâ€™s also prepare an output directory for it:\n",
    "DATA_DIRECTORY = NOTEBOOK_PATH / 'data'\n",
    "MAP_DIRECTORY = NOTEBOOK_PATH / \"MyMap\"\n",
    "MAP_DIRECTORY.mkdir(exist_ok=True)\n",
    "file_path = DATA_DIRECTORY / 'PPGIS/ExperiencePoints_All_Helsinki.shp'\n",
    "\n",
    "# read the data as a geodataframe named exp_places\n",
    "exp_places = gpd.read_file(file_path)\n",
    "print(exp_places.head(1))\n",
    "print (f\"Number of rows in our dataset: {len(exp_places)}\")\n",
    "exp_places.plot(markersize=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc6708e-baac-402e-a1ba-4a7a3755d844",
   "metadata": {},
   "source": [
    "We have several outlier points that fall well outside our study area, which is Helsinki. These outliers are not only irrelevant to our study (being outside our area of interest) but can also negatively affect the appearance of our map. Therefore, it's important to exclude them.\n",
    "\n",
    "The simplest method to achieve this is by using a polygon that defines our study area. In our case, the Helsinki polygon can be sourced from a variety of places. For our purposes, we will utilize the `osmnx` library to obtain the official boundary of Helsinki from [OpenStreetMap (OSM)](https://www.openstreetmap.org/) and convert it into a GeoDataFrame (GDF).\n",
    "\n",
    "Let's proceed to fetch the Helsinki polygon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5871eb7d-0217-4bd4-98ba-8e0eca12dc2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import the needed library\n",
    "import osmnx\n",
    "\n",
    "PLACE_NAME = \"Helsinki, Finland\"\n",
    "hel_area = osmnx.geocode_to_gdf(PLACE_NAME)\n",
    "\n",
    "# Get the polygon to the same CRS as original data (this is important as we are going to perform a spatial join)\n",
    "hel_area = hel_area.to_crs(exp_places.crs)\n",
    "assert exp_places.crs == hel_area.crs, \"CRS do not match\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dec1b6c-c7ff-44d9-9941-553db0cac250",
   "metadata": {},
   "source": [
    "Now, we will perform a spatial join using the `inner` method to retain only the points that fall `within` the Helsinki polygon. Should you need a refresher on how to perform a **Spatial Join** using Geopandas, remember to check the [AutoGIS course page](https://autogis-site.readthedocs.io/en/latest/lessons/lesson-3/spatial-join.html). This resource provides detailed instructions and examples to guide you through the process, ensuring you can confidently apply spatial joins to your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851f9aff-88cb-4479-bd5d-7cb204242a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the spatial join and extract the points which are within the polygon\n",
    "points_in_helsinki = gpd.sjoin(exp_places, hel_area, how=\"inner\", predicate='within')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c5fdee-e168-4e3c-93e3-89a483d9ad7c",
   "metadata": {},
   "source": [
    "## 1. Point map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44366daf-31ce-443e-8499-bff45ce517da",
   "metadata": {},
   "source": [
    "To enhance the context of our geospatial data, adding a basemap can be helpful. While basemaps are not always necessary for every type of map, they can help in contextualizing our data, making it easier for viewers to understand the geographical placement and surroundings of the data points. The Python library `Contextily` simplifies the process of adding a basemap to our maps created with Matplotlib. You can read more about the library and explore a list of available basemap providers [here](https://contextily.readthedocs.io/en/latest/providers_deepdive.html). Additionally, to learn how to effectively use this library, the [AutoGIS course page](https://autogis-site.readthedocs.io/en/latest/lessons/lesson-5/static-maps.html) offers detailed guidance and examples.\n",
    "\n",
    "Remember that when you are working with interenet map contents, the basemap in our case, you have to have your other layers in a compatible CRS. Hence we are projecting our data to `EPSG:3857` ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5a1ced-e9d5-44d0-9bec-21ad90b5af25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import contextily\n",
    "points_to_vis = points_in_helsinki.to_crs(\"EPSG:3857\")\n",
    "ax= points_to_vis.plot(markersize=3, color='brown')\n",
    "# Remove ticks and axis labels\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ax.set_xlabel('')\n",
    "ax.set_ylabel('')\n",
    "contextily.add_basemap(ax, source=contextily.providers.OpenStreetMap.Mapnik)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51158b8-4249-4de5-872e-2d5cd9c3e5af",
   "metadata": {},
   "source": [
    "Ensuring the integrity and accuracy of our data is an important step towards creating informative and visually appealing maps. A critical part of this process involves closely examining the data we plan to visualize, particularly focusing on key attributes that will drive our analysis and presentation. One such attribute is the \"Quality\" column within our dataset. It's essential to scrutinize the range of values this column contains, as it directly influences how we interpret and represent our geospatial data on the map. Let's take a moment to review the values in the \"Quality\" column to confirm their accuracy and consistency, ensuring they align with our mapping objectives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451a1b66-ca19-427d-a347-843584d1cf8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "points_in_helsinki.Quality.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9de9b49-4212-43db-bbc7-6ca133225c12",
   "metadata": {},
   "source": [
    "Our thorough examination has paid off, revealing that the \"Negative\" values in the \"Quality\" column have inconsistent capitalization, appearing as both \"negative\" and \"Negative.\" This variance, if left unaddressed, could skew our map's accuracy. Let's rectify this by standardizing the capitalization, ensuring our data's consistency and reliability for accurate mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd475794-1ffa-484d-bbc5-68eb8bd66f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "points_in_helsinki['Quality'] = points_in_helsinki['Quality'].replace('negative', 'Negative')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cceb65-eeda-40a8-ab88-6d8436486fbb",
   "metadata": {},
   "source": [
    "Now, we're set to refine our map with several key enhancements. In this updated version, we'll incorporate a superior basemap that complements our data's visual narrative. Additionally, we'll streamline the map's appearance by removing axis ticks and labels, creating a cleaner and more focused presentation. Finally, we'll introduce color coding for the points based on the \"Quality\" value, adding an intuitive layer of analysis that allows viewers to distinguish between positive and negative locations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1eb86e3-f16f-47cd-9575-f786ba5dcfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform to Web Mercator\n",
    "points_to_vis = points_in_helsinki.to_crs(\"EPSG:3857\")\n",
    "\n",
    "# Plotting with colors based on the 'Quality' column. \n",
    "# Go with a built in color map\n",
    "#cmap='plasma'\n",
    "\n",
    "# Or make your own\n",
    "import matplotlib.colors as mcolors\n",
    "binary_cmap = mcolors.ListedColormap([\"#db8a8a\",\"#77844c\"])\n",
    "\n",
    "ax = points_to_vis.plot(markersize=7, column='Quality', cmap=binary_cmap, legend=True, alpha = 0.8, edgecolor='none', legend_kwds={\"title\": \"Quality\", \"loc\" : \"lower right\"})\n",
    "\n",
    "# Adding a basemap\n",
    "contextily.add_basemap(ax, source=contextily.providers.CartoDB.Positron, alpha=0.8)\n",
    "\n",
    "# Remove ticks and axis labels\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ax.set_xlabel('')\n",
    "ax.set_ylabel('')\n",
    "\n",
    "# set this to off if you want to remove the frame\n",
    "ax.axis('on')\n",
    "# Adjust figure size to accommodate the legend, if necessary\n",
    "fig = ax.figure\n",
    "fig.set_size_inches(8, 6)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d506b95-5826-46af-92b6-94958207d74c",
   "metadata": {},
   "source": [
    "This looks better now. However, with datasets characterized by dense clusters of points where negative and positive (or any contradicting values) locations often overlap, the effectiveness of point maps can be somewhat questionable. Recognizing this challenge, we'll explore alternative visualization techniques in our next steps. Our goal is to enhance the representation of this PPGIS data, exploring different cartographic methods that might better convey the spatial patterns and relationships inherent in our dataset. \n",
    "**Remember our aims**: to uncover more **insightful** and **user-friendly** ways to visualize complex spatial data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2015231e-b2d0-4662-b8d2-f8e9e5405363",
   "metadata": {},
   "source": [
    "## A grid-based representation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f83307e-df60-4fde-8cd4-0d0e016c2e14",
   "metadata": {},
   "source": [
    "One effective strategy to address the challenge of overlapping and densely clustered points is by aggregating our points into larger areas. While this can often involve grouping points by real-world boundaries, such as neighborhoods, to provide a localized analysis of experiences, our current focus is on a broader view of Helsinki rather than its specific neighborhoods. To achieve this, we can construct a grid network that encompasses all our points. By aggregating our points into these grid cells, we can perform calculations that serve as the basis for our visualization. \n",
    "\n",
    "You can get a ready grid of your study area if available (e.g., from Statistics Finland). But here we are going to create our own the grid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefb123a-9503-45db-8899-0949ea75dc26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from shapely.geometry import Polygon, Point\n",
    "import numpy as np\n",
    "\n",
    "# Determine the bounds of point data\n",
    "minx, miny, maxx, maxy = points_in_helsinki.total_bounds\n",
    "\n",
    "# Grid dimensions\n",
    "grid_height = 250\n",
    "grid_width = 250\n",
    "\n",
    "# Generate the x and y coordinates for the grid\n",
    "x_coords = np.arange(minx, maxx + grid_width, grid_width)\n",
    "y_coords = np.arange(miny, maxy + grid_height, grid_height)\n",
    "\n",
    "# Initialize a list to hold the grid polygons\n",
    "grid_polygons = []\n",
    "\n",
    "for x in x_coords:\n",
    "    for y in y_coords:\n",
    "        # Define the polygon for each cell\n",
    "        polygon = Polygon([(x, y), (x+grid_width, y), (x+grid_width, y+grid_height), (x, y+grid_height)])\n",
    "        grid_polygons.append(polygon)\n",
    "\n",
    "# Create a GeoDataFrame from the grid polygons\n",
    "grid = gpd.GeoDataFrame({'geometry': grid_polygons}, crs=points_in_helsinki.crs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808ef637-06e1-4cdc-b11b-31f518994c1a",
   "metadata": {},
   "source": [
    "Having previously performed a spatial join on our data, we may now find ourselves with duplicate fields, namely `index_right` and `index_right`, which can lead to errors in subsequent spatial joins. Although one solution is to configure the spatial join (`sjoin`) to assign alternative names to these columns, a more straightforward approach is simply to remove them. Since these columns are not required for our ongoing work, dropping them from our dataset not only simplifies our data structure but also eliminates any potential for confusion or error moving forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fcdac8-8818-4100-9e47-8ddef82e124e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    points_in_helsinki = points_in_helsinki.drop(columns=['index_right'])\n",
    "except:\n",
    "    print(\"No such columns\")\n",
    "\n",
    "try:\n",
    "    grid = grid.drop(columns=['index_left'])\n",
    "except:\n",
    "    print(\"No such columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b567ee9-8b4c-430b-a167-8c3b1dad50c3",
   "metadata": {},
   "source": [
    "Now we do the spatial join:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c043ec4e-018c-44dd-9344-c00420de02d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Perform the spatial join\n",
    "joined_gdf = gpd.sjoin(grid, points_in_helsinki, how=\"inner\", predicate='contains')\n",
    "\n",
    "# Group by the grid cell index (left_index from the spatial join) and count positive and negative points\n",
    "count_df = joined_gdf.groupby(joined_gdf.index)['Quality'].apply(lambda x: x.value_counts()).unstack()\n",
    "\n",
    "# Fill NaN values with 0 (for cells that might have only positive or only negative points, or none)\n",
    "count_df = count_df.fillna(0).astype(int)\n",
    "\n",
    "count_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1c82a5-8686-4bad-bf51-fce2494a808d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Filter out grid cells that do not contain any point (both pos_cnt and neg_cnt are 0)\n",
    "count_df = count_df[(count_df['Negative'] > 0) | (count_df['Positive'] > 0)]\n",
    "\n",
    "# Join the counts back to the original grid GeoDataFrame using the grid index\n",
    "grid_with_counts = grid.join(count_df, how='inner')\n",
    "\n",
    "# Plot the grid\n",
    "grid_with_counts.plot(edgecolor='black', facecolor='none', linewidth=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71dfaaca-2c08-49f2-969e-7d6a3769d63a",
   "metadata": {},
   "source": [
    "To further refine our analysis and visualization, we aim to transform the raw counts of positive and negative points per cell into a more interpretable and visually accessible metric. An effective strategy for achieving this is the calculation of a \"positivity score.\" This score quantifies the overall sentiment of each cell on a scale where:\n",
    "\n",
    "- A score close to 1 signifies a predominantly positive sentiment,\n",
    "- A score close to -1 denotes a predominantly negative sentiment, and\n",
    "- A score around 0 reflects a neutral or balanced sentiment, indicating an equal distribution of positive and negative values.\n",
    "\n",
    "The formula for calculating the positivity score is as follows:\n",
    "\n",
    "$$\n",
    "\\text{Positivity Score} = \\frac{\\text{Positive} - \\text{Negative}}{\\text{Positive} + \\text{Negative}}\n",
    "$$\n",
    "\n",
    "By integrating this score into our visualization, we can offer a nuanced view of the spatial distribution of sentiments, enhancing the overall utility and insightfulness of our PPGIS data representation. But **remember** that this is just one way to analyze and visualize our data. Depending on what you're looking at, the kind of data you have, and the map you're working with, there could be many different methods that might work better. This approach gives us a straightforward way to get a quick sense of the overall sentiment in each area. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4c945b-8aee-43f4-9973-c6bb637c5c4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate the positivity score\n",
    "grid_with_counts['Positivity_Score'] = (grid_with_counts['Positive'] - grid_with_counts['Negative']) / (grid_with_counts['Positive'] + grid_with_counts['Negative']).replace({0: np.nan})\n",
    "\n",
    "# Handle cases where the denominator was 0 by replacing NaN with 0 or another suitable value\n",
    "grid_with_counts['Positivity_Score'] = grid_with_counts['Positivity_Score'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25ee518-9aac-4e11-8281-29c4960a0cb4",
   "metadata": {
    "tags": []
   },
   "source": [
    "Let's make a quick visualization of the values we just calculated: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbc5ea7-3380-48f0-813b-dc2f18cdeaa5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ax = grid_with_counts.plot(\n",
    "    figsize=(12, 8),\n",
    "\n",
    "    column=\"Positivity_Score\",\n",
    "    cmap=\"Spectral\",\n",
    "    linewidth=0,\n",
    "    alpha=0.8,\n",
    "\n",
    "    legend=True,\n",
    "    legend_kwds={\"label\": \"Positivity score\"}\n",
    ")\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ax.set_xlabel('')\n",
    "ax.set_ylabel('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972e84a5-a696-4b0d-8094-e10042f31dc1",
   "metadata": {},
   "source": [
    "The detailed granularity of values in our map can overwhelm the viewer, making it difficult to see meaningful patterns. To enhance interpretability, we'll simplify our data classification by adopting the [Natural Breaks method](https://en.wikipedia.org/wiki/Jenks_natural_breaks_optimization), also known as Jenks optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b9c830-1d8e-48aa-9788-512390b13e29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "grid_with_counts.plot(\n",
    "    figsize=(12, 8),\n",
    "\n",
    "    column=\"Positivity_Score\",\n",
    "    scheme=\"NaturalBreaks\",\n",
    "    cmap=\"RdYlGn\",\n",
    "    linewidth=0,\n",
    "    alpha=0.8,\n",
    "\n",
    "    legend=True,\n",
    "    legend_kwds={\"title\": \"Perception\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714d9b0f-e7f8-4e1e-b9c8-ad434765d38d",
   "metadata": {},
   "source": [
    "Let's enhance the visual appeal of our map to make it more accessible and aesthetically pleasing. Recognizing that a red and green color scheme is not ideal for individuals with color blindness, we'll select a different color palette that is more inclusive. Additionally, we'll add a basemap to provide context to our visualization. To ensure clarity, we'll position the legend carefully to avoid obscuring any important map details. We'll also adjust the transparency of our overlaying layers, achieving a balanced visual composition that allows for easy interpretation of the map's contents. \n",
    "\n",
    "If you want more customization control over your scale bar, you can use specialized libraries for this purpose. For example, the [**matplotlib-scalebar**](https://pypi.org/project/matplotlib-scalebar/) library (which is not included in the default matplotlib package and has to be installed separately) can give you more control. To install matplotlib-scalebar, you can use `pip install matplotlib-scalebar` in the Python console or `!pip install matplotlib-scalebar` inside a Jupyter notebook code cell.\n",
    "```\n",
    "#pip install matplotlib-scalebar\n",
    "import matplotlib_scalebar.scalebar as sb\n",
    "\n",
    "# Create and add the scale bar\n",
    "scalebar = sb.ScaleBar(1, units='m', location='lower left', scale_loc='bottom', box_alpha=0, color='black')\n",
    "ax.add_artist(scalebar)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47740580-79f2-4ba3-9e52-33f55cb7a7b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import contextily\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1.anchored_artists import AnchoredSizeBar\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "# we need CRS in web mercator to work with a basemap\n",
    "grid_with_counts = grid_with_counts.to_crs(\"EPSG:3857\")\n",
    "\n",
    "# Visualize\n",
    "ax = grid_with_counts.plot(\n",
    "    figsize=(12, 8),\n",
    "\n",
    "    column=\"Positivity_Score\",\n",
    "    scheme=\"NaturalBreaks\",\n",
    "    cmap=\"viridis\",\n",
    "    linewidth=0,\n",
    "    alpha=0.6,\n",
    "\n",
    "    legend=True,\n",
    "    legend_kwds={\"title\": \"Perception\", \"loc\": \"lower right\"}\n",
    ")\n",
    "\n",
    "# Remove axis\n",
    "ax.set_axis_off()\n",
    "plt.title('Environmental Perceptions in Helsinki', fontdict={'fontsize': '16', 'fontweight' : '3'})\n",
    "contextily.add_basemap(\n",
    "    ax,\n",
    "    source=contextily.providers.CartoDB.Positron,alpha=0.6,\n",
    "    attribution=(\"Data: SoftGIS team, Aalto University ; OSM\")\n",
    ")\n",
    "\n",
    "# Helsinki's latitude\n",
    "latitude = 60\n",
    "# Calculate the scale correction factor for the Mercator distortion\n",
    "scale_correction = 1 / np.cos(np.radians(latitude))\n",
    "# Adjust the scale bar length accordingly\n",
    "adjusted_length = 1000 * scale_correction\n",
    "# length without adjustment\n",
    "length=1000\n",
    "\n",
    "\n",
    "# Add a scale bar with AnchoredSizeBar\n",
    "fontprops = fm.FontProperties(size=10)\n",
    "scalebar = AnchoredSizeBar(ax.transData,\n",
    "                           length,  # Length of the bar in data units\n",
    "                           '1 km',  # Label for the scale bar\n",
    "                           'upper right',  # Location of the scale bar\n",
    "                           pad=0.1,\n",
    "                           color='black',\n",
    "                           frameon=False,\n",
    "                           size_vertical=1,\n",
    "                           fontproperties=fontprops)\n",
    "\n",
    "ax.add_artist(scalebar)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0562c19c-63f5-4202-bb30-434255a58044",
   "metadata": {},
   "source": [
    "> **Wait!**\n",
    ">\n",
    "> Do you notice something odd about the scale bar?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6657f8-dcc3-407b-99ec-1fcb89db2e39",
   "metadata": {},
   "source": [
    "### Adding landmarks: custom symbols and labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3022bb7f-16a9-4aa2-845c-1e1099addc38",
   "metadata": {},
   "source": [
    "To make our map more user-friendly and easier to navigate, incorporating landmarks can significantly enhance spatial orientation. By highlighting well-known places, users can quickly identify specific areas of interest within Helsinki. While we'll manually add a few landmarks using their coordinates for demonstration purposes, it's worth noting that such data can also be sourced from platforms like OpenStreetMap (OSM). As a first step, we'll create GeoDataFrames for these landmarks, setting the stage for a more informative and navigable map visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddb3a0f-9c3d-4c67-9b72-577a58707508",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "landmarks_dict = {\n",
    "    'Helsinki White Church': (60.1695, 24.9514),\n",
    "    'Pasila Railway Station': (60.1989, 24.9332),  \n",
    "    'Itis': (60.2106, 25.0832)\n",
    "}\n",
    "\n",
    "# Create a GeoDataFrame\n",
    "landmarks = gpd.GeoDataFrame({\n",
    "    'name': landmarks_dict.keys(),\n",
    "    'geometry': [Point(xy[::-1]) for xy in landmarks_dict.values()]  \n",
    "})\n",
    "\n",
    "# the coordinates are in WGS84 (EPSG:4326)\n",
    "landmarks.set_crs(epsg=4326, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cbe4a0-88c9-4cb4-a4c5-ca5ab8d39734",
   "metadata": {},
   "source": [
    "We will now integrate the landmarks using custom symbols, such as specific images that represent each landmark. This visual enhancement not only adds an element of realism but also makes the map more engaging and recognizable. Alongside these symbols, we'll include labels for each landmark to ensure users can easily identify these notable places. This combination of custom imagery and clear labeling can enhance the user's ability to navigate and understand the spatial layout of Helsinki within our map. Specially if they are not very familiar with the area.\n",
    "\n",
    "Initially, we'll introduce the landmarks onto the map using star symbols. Following this, we'll further personalize the visualization by incorporating custom images for each landmark. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f0bff5-abee-4358-896f-bea1ee252212",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ax = grid_with_counts.plot(\n",
    "    figsize=(12, 8),\n",
    "    column=\"Positivity_Score\",\n",
    "    scheme=\"NaturalBreaks\",\n",
    "    cmap=\"viridis\",\n",
    "    linewidth=0,\n",
    "    alpha=0.6,\n",
    "    legend=True,\n",
    "    legend_kwds={\"title\": \"Positivity Score\", \"loc\": \"lower right\"}\n",
    ")\n",
    "\n",
    "# Convert landmarks to the same CRS\n",
    "landmarks = landmarks.to_crs(\"EPSG:3857\")\n",
    "\n",
    "# Plot landmarks as stars on the map\n",
    "landmarks.plot(ax=ax, marker='*', color='orange', markersize=100, label='Landmarks')\n",
    "\n",
    "# Label landmarks using the 'name' column\n",
    "for x, y, label in zip(landmarks.geometry.x, landmarks.geometry.y, landmarks['name']):\n",
    "    ax.text(x, y, label, fontsize=8, ha='right', va='bottom')\n",
    "\n",
    "# Remove axis\n",
    "ax.set_axis_off()\n",
    "\n",
    "# Set title\n",
    "plt.title('Environmental Perceptions in Helsinki', fontdict={'fontsize': '16', 'fontweight': '3'})\n",
    "\n",
    "# Add basemap\n",
    "contextily.add_basemap(\n",
    "    ax,\n",
    "    source=contextily.providers.CartoDB.Positron,\n",
    "    alpha=0.6,\n",
    "    attribution=(\"Data: SoftGIS team, Aalto University\")\n",
    ")\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36d3fc9-68e5-48ac-8a39-50ff119490e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "\n",
    "# Function to add an image at a given location on the map\n",
    "def add_image_at_location(ax, filepath, coord, zoom):\n",
    "    img = plt.imread(filepath)\n",
    "    imagebox = OffsetImage(img, zoom=zoom)\n",
    "    ab = AnnotationBbox(imagebox, coord, frameon=False, bboxprops=dict(edgecolor='none'))\n",
    "    ax.add_artist(ab)\n",
    "\n",
    "ax = grid_with_counts.plot(\n",
    "    figsize=(12, 8),\n",
    "    column=\"Positivity_Score\",\n",
    "    scheme=\"NaturalBreaks\",\n",
    "    cmap=\"viridis\",\n",
    "    linewidth=0,\n",
    "    alpha=0.6,\n",
    "    legend=True,\n",
    "    legend_kwds={\"title\": \"  Positivity Score\", \"loc\": \"lower right\", \"frameon\" : False,\"fancybox\" : False}\n",
    ")\n",
    "\n",
    "# Convert landmarks to the same CRS\n",
    "landmarks = landmarks.to_crs(\"EPSG:3857\")\n",
    "\n",
    "# Custom icons for each landmark\n",
    "icons = {\n",
    "    'Itis': \"assets/icons/shop.png\",\n",
    "    'Helsinki White Church': \"assets/icons/church.png\",\n",
    "    'Pasila Railway Station': \"assets/icons/train.png\"\n",
    "}\n",
    "\n",
    "# Plot each landmark with its custom icon\n",
    "for _, row in landmarks.iterrows():\n",
    "    x, y = row.geometry.x, row.geometry.y\n",
    "    name = row['name']\n",
    "    if name in icons:\n",
    "        add_image_at_location(ax, icons[name], (x, y), zoom=0.04)\n",
    "        if name != \"Itis\":\n",
    "            ax.text(x + 9300, y - 200, name, fontsize=9, ha='right', va='bottom')\n",
    "        else:\n",
    "            ax.text(x -1200, y - 200, name, fontsize=9, ha='right', va='bottom')\n",
    "    else:\n",
    "        # Plot with a default marker if no icon is specified\n",
    "        ax.plot(x, y, marker='*', color='orange', markersize=10, label='Landmarks')\n",
    "        ax.text(x, y, name, fontsize=8, ha='right', va='bottom')\n",
    "\n",
    "# Remove axis\n",
    "ax.set_axis_off()\n",
    "\n",
    "# Set title\n",
    "plt.title('Environmental Perceptions in Helsinki', fontdict={'fontsize': '16', 'fontweight': '3'})\n",
    "\n",
    "# Add basemap\n",
    "contextily.add_basemap(\n",
    "    ax,\n",
    "    source=contextily.providers.CartoDB.Positron,\n",
    "    alpha=0.6,\n",
    "    attribution=(\" Data: SoftGIS team, Aalto University\")\n",
    ")\n",
    "\n",
    "# Adjust the view to zoom out a bit\n",
    "ax.set_xlim(ax.get_xlim()[0] - 5000, ax.get_xlim()[1] + 5000)\n",
    "ax.set_ylim(ax.get_ylim()[0] - 5000, ax.get_ylim()[1] + 5000)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b41e97c-3ed9-467c-bc9b-c8b297ab7142",
   "metadata": {},
   "source": [
    "## Kernel density map\n",
    "A kernel density map, or a heat map, visualizes the density of data points across a geographical area, smoothing them over a surface to indicate concentrations. This method can be useful for our dataset, where positive and negative points frequently overlap, making it challenging to distinguish patterns with traditional point maps. By applying [kernel density estimation (KDE)](https://en.wikipedia.org/wiki/Kernel_density_estimation), we can transform these overlapping points into a continuous density surface, highlighting areas with high concentrations of either positive or negative feedback. \n",
    "\n",
    "For this part of our tutorial we will work with two new libraries:\n",
    "- **TileMapBase**: Another library for adding basemaps to our maps\n",
    "- **Seaborn**: A higher-level library based on Matplotlib for creating attractive statistical graphics and maps\n",
    "\n",
    "`TileMapBase` and `Contextily` are both Python libraries designed to enhance geospatial visualizations by adding basemaps to plots, but they serve this purpose in slightly different ways and contexts. `TileMapBase` offers a flexible, if somewhat manual, approach to map tile integration, suitable for a variety of visualization needs. `Contextily`, on the other hand, focuses on ease of use and integration with geospatial data, making it a go-to for quickly adding rich, contextual backgrounds to static maps. The choice between them depends on your specific project requirements, preferred workflow, and the level of customization you need.\n",
    "\n",
    "Creating similar maps as part of a repetitive process (e.g., generating separate kernel density maps for place experiences in each neighborhood of Helsinki), benefits greatly from writing your code in a modular fashion. By encapsulating parts of the map creation process that are repeatable into functions, you streamline the workflow, making it more efficient to produce similar maps. For instance, the code in the cell below demonstrates how segmenting the mapping process into a callable function can simplify generating these maps with varied inputs by merely executing the function with different parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7650f9-aa0d-4f2e-a05b-f7b1cdba0e76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tilemapbase\n",
    "import seaborn as sns\n",
    "\n",
    "tilemapbase.init(create=True)\n",
    "\n",
    "def plot_map(fig, ax, points_plot, polygons_plot, file_name, extent, leg):\n",
    "    \"\"\"\n",
    "    A short helper function that takes points and polygons as input\n",
    "    and creates a plot with a basemap.\n",
    "    \"\"\"\n",
    "\n",
    "    plotter = tilemapbase.Plotter(extent, tilemapbase.tiles.Carto_Light, width=1000)\n",
    "    # Hide the ticks\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "    # Hide the axis labels \n",
    "    ax.set_xlabel('')\n",
    "    ax.set_ylabel('')\n",
    "    plotter.plot(ax)\n",
    "    if leg:\n",
    "        # Create and add a color bar\n",
    "        norm = plt.Normalize(vmin=density_plot.collections[0].get_array().min(), vmax=density_plot.collections[0].get_array().max())\n",
    "        sm = plt.cm.ScalarMappable(cmap=\"viridis\", norm=norm)\n",
    "        sm.set_array([])\n",
    "        # Create colorbar\n",
    "        cbar = fig.colorbar(sm, ax=ax, orientation='vertical', fraction=0.02, pad=0.07)\n",
    "        # Remove colorbar ticks\n",
    "        cbar.set_ticks([])\n",
    "        # Label 'Higher density' at the top and 'Lower density' at the bottom of the colorbar\n",
    "        cbar.set_label('Density', rotation=270, labelpad=15)\n",
    "        cbar.ax.text(0.5, 1.05, 'Higher density', ha='center', va='bottom', transform=cbar.ax.transAxes)\n",
    "        cbar.ax.text(0.5, -0.05, 'Lower density', ha='center', va='top', transform=cbar.ax.transAxes)\n",
    "\n",
    "    if polygons_plot is not None:\n",
    "        polygons_plot.plot(ax=ax, edgecolor='red', facecolor='none')  # Customize as needed\n",
    "\n",
    "    if points_plot is not None:\n",
    "        points_plot.plot(ax=ax, marker='o', color='blue', markersize=5)  # Customize as needed\n",
    "\n",
    "    # Save the figure\n",
    "    if file_name is not None:\n",
    "        fig.savefig(MAP_DIRECTORY / f'{file_name}.png', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ab4462-e4b6-4023-be74-a527c9e7a0ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the points from the Helsinki dataset\n",
    "points = points_in_helsinki\n",
    "\n",
    "# Create a figure and axis for plotting \n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "# Reproject the points to the Web Mercator projection for compatibility with web-based tile services\n",
    "points = points.to_crs(\"EPSG:3857\")\n",
    "\n",
    "# Calculate the extent of the points with an additional buffer for margin\n",
    "extent = tilemapbase.extent_from_frame(points, buffer=5)\n",
    "\n",
    "# Create a kernel density estimate (KDE) plot of the points\n",
    "\n",
    "density_plot = sns.kdeplot(\n",
    "    x=points[\"geometry\"].x,  # X coordinates of points\n",
    "    y=points[\"geometry\"].y,  # Y coordinates of points\n",
    "    fill=True,  # Fill the area under the KDE curve; 'fill=True' replaces 'shade=True' in newer seaborn versions\n",
    "    alpha=0.5,  # Set the transparency of the KDE plot\n",
    "    cmap=\"viridis\",  # Color map to use for the KDE plot\n",
    "    zorder=3,  # Drawing order: ensures the KDE plot is drawn above other layers\n",
    "    ax=ax  # Specify the Matplotlib axes object where the plot should be drawn\n",
    ")\n",
    "\n",
    "# Now we use our custom function to draw our map\n",
    "plot_map(fig, ax, None, None, \"KDE_Map\", extent, leg = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2f1470-2326-4c7a-b60c-b46f7637cc27",
   "metadata": {},
   "source": [
    "We've previously generated a KDE map that includes all points, without distinguishing between Positive and Negative qualities. To deepen our analysis, we'll next produce two separate KDE maps, one for each quality type. By overlaying these maps with a degree of transparency, we aim to achieve a visual comparison between the two distributions. Additionally, we'll select a more neutral basemap to ensure that it complements rather than competes with our overlays, allowing for a clearer and more focused visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f612cb02-9d8a-484f-bf93-0b4596f1aa4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matplotlib.patches import Patch\n",
    "\n",
    "# Ensure your points GeoDataFrame is in the correct CRS (EPSG:3857) for contextily\n",
    "points = points_in_helsinki.to_crs(\"EPSG:3857\")\n",
    "\n",
    "# Filter points by category\n",
    "positive_points = points[points['Quality'] == 'Positive']\n",
    "negative_points = points[points['Quality'] == 'Negative']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "# KDE plot for Negative points\n",
    "sns.kdeplot(\n",
    "    x=negative_points[\"geometry\"].x,\n",
    "    y=negative_points[\"geometry\"].y,\n",
    "    fill=True,\n",
    "    alpha=0.5,\n",
    "    cmap=\"Oranges\",\n",
    "    zorder=3,\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "# KDE plot for Positive points\n",
    "sns.kdeplot(\n",
    "    x=positive_points[\"geometry\"].x,\n",
    "    y=positive_points[\"geometry\"].y,\n",
    "    fill=True,\n",
    "    alpha=0.3,\n",
    "    cmap=\"Blues\",\n",
    "    zorder=3,\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "# Add a simpler basemap with contextily\n",
    "contextily.add_basemap(ax, source=contextily.providers.CartoDB.Positron, zorder=1)\n",
    "\n",
    "# Add custom legend using Patch\n",
    "legend_elements = [\n",
    "    Patch(facecolor='blue', edgecolor='blue', alpha=0.5, label='Positive'),\n",
    "    Patch(facecolor='orange', edgecolor='orange', alpha=0.3, label='Negative')\n",
    "]\n",
    "ax.legend(handles=legend_elements, title='Quality', loc='upper right', fontsize='large', title_fontsize='x-large')\n",
    "\n",
    "# Customize the plot\n",
    "ax.set_xlabel('')\n",
    "ax.set_ylabel('')\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "plt.title('Density of Positive vs Negative Points in Helsinki', fontsize=16)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the figure\n",
    "fig.savefig(MAP_DIRECTORY / 'overlay_pos_neg.png', bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a554812d-fc51-4ce8-a4f8-d1787ea15af7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
